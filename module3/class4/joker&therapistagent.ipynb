{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f90284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\") \n",
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f22ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state for our graph\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    agent_type: str  # Will store which agent was selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14650e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.7,\n",
    "    google_api_key=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8241f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router function - decides which agent to use based on the first message\n",
    "def route_to_agent(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes the first user message and decides whether to route to therapist or joker.\n",
    "    \"\"\"\n",
    "    # Get the first user message\n",
    "    user_message = state[\"messages\"][0].content\n",
    "    \n",
    "    # Use LLM to decide which agent to use\n",
    "    routing_prompt = f\"\"\"Based on the following user message, decide if the user needs:\n",
    "- A THERAPIST (for emotional support, mental health, serious problems, advice)\n",
    "- A JOKER (for jokes, humor, entertainment, fun)\n",
    "\n",
    "User message: \"{user_message}\"\n",
    "\n",
    "Respond with ONLY one word: either \"therapist\" or \"joker\".\"\"\"\n",
    "    \n",
    "    response = llm.invoke(routing_prompt)\n",
    "    decision = response.content.strip().lower()\n",
    "    \n",
    "    # Return the agent type\n",
    "    if \"therapist\" in decision:\n",
    "        return \"therapist\"\n",
    "    else:\n",
    "        return \"joker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e06dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Therapist Node\n",
    "def therapist_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Acts as a compassionate therapist providing emotional support.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Create therapist system prompt\n",
    "    therapist_prompt = \"\"\"You are a compassionate and professional therapist. \n",
    "Your role is to:\n",
    "- Listen actively and empathetically\n",
    "- Provide emotional support and validation\n",
    "- Ask thoughtful questions to understand the person better\n",
    "- Offer helpful coping strategies when appropriate\n",
    "- Maintain a warm, caring, and professional tone\n",
    "\n",
    "Respond to the user's message with empathy and understanding.\"\"\"\n",
    "    \n",
    "    # Combine system prompt with user messages\n",
    "    full_messages = [HumanMessage(content=therapist_prompt)] + list(messages)\n",
    "    \n",
    "    # Get response from LLM\n",
    "    response = llm.invoke(full_messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"agent_type\": \"therapist\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eea37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joker Node\n",
    "def joker_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Acts as a funny comedian providing jokes and humor.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Create joker system prompt\n",
    "    joker_prompt = \"\"\"You are a hilarious comedian and joker.\n",
    "Your role is to:\n",
    "- Make people laugh with clever jokes and witty responses\n",
    "- Use wordplay, puns, and humor\n",
    "- Keep things light and entertaining\n",
    "- Be creative and spontaneous with your comedy\n",
    "- Stay positive and fun\n",
    "\n",
    "Respond to the user's message with humor and jokes.\"\"\"\n",
    "    \n",
    "    # Combine system prompt with user messages\n",
    "    full_messages = [HumanMessage(content=joker_prompt)] + list(messages)\n",
    "    \n",
    "    # Get response from LLM\n",
    "    response = llm.invoke(full_messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"agent_type\": \"joker\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56014aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"therapist\", therapist_node)\n",
    "workflow.add_node(\"joker\", joker_node)\n",
    "\n",
    "# Set entry point with conditional routing\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_to_agent,\n",
    "    {\n",
    "        \"therapist\": \"therapist\",\n",
    "        \"joker\": \"joker\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edges to END after each agent responds\n",
    "workflow.add_edge(\"therapist\", END)\n",
    "workflow.add_edge(\"joker\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph (optional)\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not visualize graph: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8996709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Message that should route to therapist\n",
    "print(\"=\" * 50)\n",
    "print(\"TEST 1: Routing to Therapist\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "initial_state_therapist = {\n",
    "    \"messages\": [HumanMessage(content=\"I'm feeling really stressed about work and life lately\")],\n",
    "    \"agent_type\": \"\"\n",
    "}\n",
    "\n",
    "result_therapist = graph.invoke(initial_state_therapist)\n",
    "print(f\"\\nAgent selected: {result_therapist['agent_type']}\")\n",
    "print(f\"\\nResponse: {result_therapist['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Message that should route to joker\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TEST 2: Routing to Joker\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "initial_state_joker = {\n",
    "    \"messages\": [HumanMessage(content=\"Tell me a funny joke to brighten my day!\")],\n",
    "    \"agent_type\": \"\"\n",
    "}\n",
    "\n",
    "result_joker = graph.invoke(initial_state_joker)\n",
    "print(f\"\\nAgent selected: {result_joker['agent_type']}\")\n",
    "print(f\"\\nResponse: {result_joker['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616668c",
   "metadata": {},
   "source": [
    "## How This Works\n",
    "\n",
    "This LangGraph implementation demonstrates:\n",
    "\n",
    "1. **State Management**: Uses `AgentState` to track messages and agent type\n",
    "2. **Conditional Routing**: The `route_to_agent` function uses Gemini LLM to analyze the first message and decide which agent to invoke\n",
    "3. **Two Agent Nodes**:\n",
    "   - **Therapist Node**: Provides empathetic emotional support\n",
    "   - **Joker Node**: Delivers humor and entertainment\n",
    "4. **Graph Flow**: \n",
    "   - START → Router (conditional) → Therapist OR Joker → END\n",
    "\n",
    "The LLM intelligently routes based on the user's intent detected in their first message."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
